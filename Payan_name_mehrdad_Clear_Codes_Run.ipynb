{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Payan_name_mehrdad.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fnWD92MoaEa9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJannesar/CNN_AdaBoost/blob/master/Payan_name_mehrdad_Clear_Codes_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DrrMZBR3u8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "ed2d4cb4-498d-4388-b076-be2f8efc387b"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (41.6.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.1.1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEVpxY6lP14f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "34a75c2b-5a91-4516-e47f-9f022de7a5d5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "from keras.models import Model,Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Activation,Dropout,Conv1D,GlobalMaxPooling1D,GRU,Bidirectional,LSTM,SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K \n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn import model_selection"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1w9nDwwhTAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set parameters:\n",
        "max_features = 5000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 2\n",
        "embedding_vecor_length = 32\n",
        "units = 128\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qcdGwoDSC7u",
        "colab_type": "text"
      },
      "source": [
        "## Create Models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fWeENwJgMuB",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blSwy1ONf4c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "d1a4ff29-c481-46e0-8768-bab120edca0c"
      },
      "source": [
        "def fit_model_BG(optimizer='adam'):\n",
        "  model_BG = Sequential()\n",
        "  model_BG.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BG.add(Bidirectional(GRU(100)))\n",
        "  model_BG.add(Dense(1, activation='sigmoid'))\n",
        "  model_BG.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model_BG\n",
        "\n",
        "\n",
        "model_BG = KerasClassifier(build_fn=fit_model_BG,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BG_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BG_grid = GridSearchCV(model_BG,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BG_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BG_summary = fit_model_BG()\n",
        "print(model_BG_summary.summary())\n",
        "\n",
        "\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BG.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BG = model_BG.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_GRU = np.argmax(X_test, axis=1)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               79800     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 240,001\n",
            "Trainable params: 240,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-v2UwM6ggDK",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMoGUHcbgkPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4c70661b-66a6-48e6-b74b-532db555f6c1"
      },
      "source": [
        "def fit_model_BL(optimizer='adam'):\n",
        "  model_BL = Sequential()\n",
        "  model_BL.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BL.add(Bidirectional(LSTM(100)))\n",
        "  model_BL.add(Dense(1, activation='sigmoid'))\n",
        "  model_BL.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model_BL\n",
        "\n",
        "model_BL = KerasClassifier(build_fn=fit_model_BL,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BL_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BL_grid = GridSearchCV(model_BL,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BL_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BL_summary = fit_model_BL()\n",
        "print(model_BL_summary.summary())\n",
        "\n",
        "# print(model_BL.summary())\n",
        "# model_BL.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BL.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BL = model_BL.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_LSTM = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 200)               106400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 266,601\n",
            "Trainable params: 266,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9J0iwYyguNJ",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6YkGa1jgwvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3842a1c5-0139-4aa6-d65e-b949de6a1f15"
      },
      "source": [
        "def fit_model_BR(optimizer='adam'):\n",
        "  model_BR = Sequential()\n",
        "  model_BR.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BR.add(Bidirectional(SimpleRNN(100)))\n",
        "  model_BR.add(Dense(1, activation='sigmoid'))\n",
        "  model_BR.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_BR\n",
        "\n",
        "model_BR = KerasClassifier(build_fn=fit_model_BR,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BR_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BR_grid = GridSearchCV(model_BR,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BR_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BR_summary = fit_model_BR()\n",
        "print(model_BR_summary.summary())\n",
        "\n",
        "\n",
        "# print(model_BR.summary())\n",
        "# model_BR.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BR.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BR = model_BR.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_RNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 200)               26600     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 186,801\n",
            "Trainable params: 186,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPIK59y1g9OY",
        "colab_type": "text"
      },
      "source": [
        "# LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voXaUD2QhBtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "33bd84ba-cd2f-45d3-d819-53301f5b2ee0"
      },
      "source": [
        "def fit_model_L(optimizer='adam'):\n",
        "  model_L = Sequential()\n",
        "  model_L.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_L.add(LSTM(100))\n",
        "  model_L.add(Dense(1, activation='sigmoid'))\n",
        "  model_L.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_L\n",
        "\n",
        "model_L = KerasClassifier(build_fn=fit_model_L,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_L_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_L_grid = GridSearchCV(model_L,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_L_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_L_summary = fit_model_L()\n",
        "print(model_L_summary.summary())\n",
        "\n",
        "\n",
        "\n",
        "# print(model_L.summary())\n",
        "# model_L.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_L.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_L = model_L.predict(X_test)\n",
        "\n",
        "# test_uniq_LSTM = np.argmax(X_test, axis=1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfRX1cL3hG1d",
        "colab_type": "text"
      },
      "source": [
        "# SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFXukTQhhKQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "76e23cfe-5ae8-4b17-d594-171e445547cf"
      },
      "source": [
        "def fit_model_SR(optimizer='adam'):\n",
        "  model_SR = Sequential()\n",
        "  model_SR.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_SR.add(SimpleRNN(100))\n",
        "  model_SR.add(Dense(1, activation='sigmoid'))\n",
        "  model_SR.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_SR\n",
        "\n",
        "\n",
        "model_SR = KerasClassifier(build_fn=fit_model_SR,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_SR_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_SR_grid = GridSearchCV(model_SR,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_SR_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_SR_summary = fit_model_SR()\n",
        "print(model_SR_summary.summary())\n",
        "\n",
        "\n",
        "\n",
        "# print(model_SR.summary())\n",
        "# model_SR.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_SR.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_SR = model_SR.predict(X_test)\n",
        "\n",
        "# test_uniq_SimpleRNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 100)               13300     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVNW0Dzv29U3",
        "colab_type": "text"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6iAuwFSkc2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "574dbf31-e843-44b7-edcb-9e5f8703daf0"
      },
      "source": [
        "def fit_model_GRU(optimizer='adam'):\n",
        "  model_GRU = Sequential()\n",
        "  model_GRU.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_GRU.add(SimpleRNN(100))\n",
        "  model_GRU.add(Dense(1, activation='sigmoid'))\n",
        "  model_GRU.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_GRU\n",
        "\n",
        "\n",
        "model_GRU = KerasClassifier(build_fn=fit_model_GRU,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_GRU_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_GRU_grid = GridSearchCV(model_GRU,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_GRU_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_GRU_summary = fit_model_GRU()\n",
        "print(model_GRU_summary.summary())\n",
        "\n",
        "\n",
        "# print(model_GRU.summary())\n",
        "# model_GRU.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_GRU.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_GRU = model_GRU.predict(X_test)\n",
        "\n",
        "# test_uniq_SimpleRNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, 100)               13300     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoaICbw7ZXLL",
        "colab_type": "text"
      },
      "source": [
        "## LSTM ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0DUTDNNErrf",
        "colab_type": "code",
        "outputId": "333a4175-a946-44b0-d70d-92afd57b031a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "def fit_model_L_A(optimizer='adam'):\n",
        "  input_ = keras.layers.Input(shape=[max_review_length], dtype='int32')\n",
        "\n",
        "  # get the embedding layer\n",
        "  embedded = Embedding(\n",
        "          input_dim=top_words,\n",
        "          output_dim=32,\n",
        "          input_length=max_review_length,\n",
        "          trainable=False,\n",
        "          mask_zero=False\n",
        "      )(input_)\n",
        "\n",
        "  activations = LSTM(units, return_sequences=True)(embedded)\n",
        "\n",
        "  # compute importance for each step\n",
        "  attention = Dense(1, activation='tanh')(activations)\n",
        "  attention = keras.layers.Flatten()(attention)\n",
        "  attention = keras.layers.Activation('softmax')(attention)\n",
        "  attention = keras.layers.RepeatVector(units)(attention)\n",
        "  attention = keras.layers.Permute([2, 1])(attention)\n",
        "\n",
        "  multiply_layer = keras.layers.Multiply()\n",
        "  sent_representation = multiply_layer([activations, attention])\n",
        "  # sent_representation = keras.layers.Multiply([activations, attention])\n",
        "  sent_representation = keras.layers.Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(sent_representation)\n",
        "\n",
        "  probabilities = Dense(1, activation='sigmoid')(sent_representation)\n",
        "  model_L_A = Model(input=input_, output=probabilities)\n",
        "  model_L_A.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "\n",
        "  return model_L_A\n",
        "\n",
        "\n",
        "\n",
        "model_L_A = KerasClassifier(build_fn=fit_model_L_A,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_L_A_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_L_A_grid = GridSearchCV(model_L_A,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_L_A_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "model_L_A_summary = fit_model_L_A()\n",
        "print(model_L_A_summary.summary())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 500)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 500, 32)      160000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 500, 128)     82432       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500, 1)       129         lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 500)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 500)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 128, 500)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 500, 128)     0           repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 500, 128)     0           lstm_3[0][0]                     \n",
            "                                                                 permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 128)          0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 242,690\n",
            "Trainable params: 82,690\n",
            "Non-trainable params: 160,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TnzD2dub2PI",
        "colab_type": "text"
      },
      "source": [
        "# Text_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMaib8lHotb2",
        "colab_type": "code",
        "outputId": "0485f7ed-2fdd-4585-f7e3-89d1bbe3e25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "def fit_model_text_CNN(optimizer='adam'):\n",
        "  model_text_CNN = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "  model_text_CNN.add(Embedding(max_features,\n",
        "                      embedding_dims,\n",
        "                      input_length=maxlen))\n",
        "  model_text_CNN.add(Dropout(0.2))\n",
        "\n",
        "  # we add a Convolution1D, which will learn filters\n",
        "  # word group filters of size filter_length:\n",
        "  model_text_CNN.add(Conv1D(filters,\n",
        "                  kernel_size,\n",
        "                  padding='SAME',\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  # we use max pooling:\n",
        "  model_text_CNN.add(GlobalMaxPooling1D())\n",
        "\n",
        "  # We add a vanilla hidden layer:\n",
        "  model_text_CNN.add(Dense(hidden_dims))\n",
        "  model_text_CNN.add(Dropout(0.2))\n",
        "  model_text_CNN.add(Activation('relu'))\n",
        "\n",
        "  # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "  model_text_CNN.add(Dense(1))\n",
        "  model_text_CNN.add(Activation('sigmoid'))\n",
        "\n",
        "  model_text_CNN.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model_text_CNN\n",
        "\n",
        "\n",
        "model_text_CNN = KerasClassifier(build_fn=fit_model_text_CNN,\n",
        "                        epochs=1, \n",
        "                        batch_size=5,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_text_CNN_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_text_CNN_grid = GridSearchCV(model_text_CNN,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_text_CNN_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "model_text_CNN_summary = fit_model_text_CNN()\n",
        "print(model_text_CNN_summary.summary())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 500, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 251       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 350,751\n",
            "Trainable params: 350,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNx3D8RRWxJz",
        "colab_type": "text"
      },
      "source": [
        "# StackingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2vvXmpBZ23l",
        "colab_type": "text"
      },
      "source": [
        "## Running GridSearch Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeAZY7P_F6pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_BG_grid_results = model_BG_grid.fit(X_train, y_train)\n",
        "model_BL_grid_results = model_BL_grid.fit(X_train, y_train)\n",
        "model_BR_grid_results = model_BR_grid.fit(X_train, y_train)\n",
        "model_L_grid_results = model_L_grid.fit(X_train, y_train)\n",
        "model_SR_grid_results = model_SR_grid.fit(X_train, y_train)\n",
        "model_GRU_grid_results = model_GRU_grid.fit(X_train, y_train)\n",
        "model_L_A_grid_results = model_L_A_grid.fit(X_train, y_train)\n",
        "model_text_CNN_grid_results = model_text_CNN_grid.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_iBDMihZ_K4",
        "colab_type": "text"
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbtFKnDBMxkl",
        "colab_type": "code",
        "outputId": "e779f5ff-555a-4f6d-bed8-cfaf6af5eb52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf1 = grid_results\n",
        "clf2 = RandomForestClassifier(random_state=1, n_estimators=300)\n",
        "clf3 = GaussianNB()\n",
        "# Logit will be used for stacking\n",
        "lr = LogisticRegression(solver='lbfgs')\n",
        "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr, use_probas=True, cv=2)\n",
        "\n",
        "# Do CV\n",
        "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
        "                      ['grid_results', \n",
        "                       'Random Forest', \n",
        "                       'Naive Bayes',\n",
        "                       'StackingClassifier']):\n",
        "\n",
        "    scores = model_selection.cross_val_score(clf, X_train, y_train, cv=2, scoring='roc_auc')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "\n",
        "# Fit on train data / predict on test data\n",
        "sclf_fit = sclf.fit(X_train, y_train)\n",
        "mypreds = sclf_fit.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 11s - loss: 0.5177 - acc: 0.7213\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.5027 - acc: 0.7384\n",
            "Epoch 1/1\n",
            " - 20s - loss: 0.4251 - acc: 0.7909\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.5076 - acc: 0.7302\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.4977 - acc: 0.7416\n",
            "Epoch 1/1\n",
            " - 21s - loss: 0.4331 - acc: 0.7869\n",
            "Accuracy: 0.94 (+/- 0.00) [grid_results]\n",
            "Accuracy: 0.56 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.51 (+/- 0.00) [Naive Bayes]\n",
            "Epoch 1/1\n",
            " - 7s - loss: 0.5681 - acc: 0.6813\n",
            "Epoch 1/1\n",
            " - 7s - loss: 0.6009 - acc: 0.6525\n",
            "Epoch 1/1\n",
            " - 12s - loss: 0.5061 - acc: 0.7397\n",
            "Epoch 1/1\n",
            " - 7s - loss: 0.6030 - acc: 0.6400\n",
            "Epoch 1/1\n",
            " - 7s - loss: 0.6023 - acc: 0.6426\n",
            "Epoch 1/1\n",
            " - 12s - loss: 0.5127 - acc: 0.7354\n",
            "Epoch 1/1\n",
            " - 12s - loss: 0.5118 - acc: 0.7163\n",
            "Epoch 1/1\n",
            " - 12s - loss: 0.5063 - acc: 0.7299\n",
            "Epoch 1/1\n",
            " - 22s - loss: 0.4206 - acc: 0.7939\n",
            "Epoch 1/1\n",
            " - 8s - loss: 0.5950 - acc: 0.6579\n",
            "Epoch 1/1\n",
            " - 8s - loss: 0.5900 - acc: 0.6614\n",
            "Epoch 1/1\n",
            " - 13s - loss: 0.5090 - acc: 0.7259\n",
            "Epoch 1/1\n",
            " - 8s - loss: 0.5813 - acc: 0.6678\n",
            "Epoch 1/1\n",
            " - 8s - loss: 0.5830 - acc: 0.6627\n",
            "Epoch 1/1\n",
            " - 13s - loss: 0.5045 - acc: 0.7210\n",
            "Epoch 1/1\n",
            " - 13s - loss: 0.4956 - acc: 0.7451\n",
            "Epoch 1/1\n",
            " - 13s - loss: 0.5183 - acc: 0.7227\n",
            "Epoch 1/1\n",
            " - 24s - loss: 0.4353 - acc: 0.7866\n",
            "Accuracy: 0.94 (+/- 0.00) [StackingClassifier]\n",
            "Epoch 1/1\n",
            " - 14s - loss: 0.5011 - acc: 0.7286\n",
            "Epoch 1/1\n",
            " - 14s - loss: 0.4980 - acc: 0.7395\n",
            "Epoch 1/1\n",
            " - 24s - loss: 0.4342 - acc: 0.7838\n",
            "Epoch 1/1\n",
            " - 14s - loss: 0.5109 - acc: 0.7182\n",
            "Epoch 1/1\n",
            " - 15s - loss: 0.5048 - acc: 0.7312\n",
            "Epoch 1/1\n",
            " - 24s - loss: 0.4268 - acc: 0.7905\n",
            "Epoch 1/1\n",
            " - 25s - loss: 0.4215 - acc: 0.7930\n",
            "Epoch 1/1\n",
            " - 25s - loss: 0.4411 - acc: 0.7820\n",
            "Epoch 1/1\n",
            " - 47s - loss: 0.3677 - acc: 0.8279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-62c3b1a8fc74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Fit on train data / predict on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0msclf_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmypreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msclf_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreddata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'preddata' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWD92MoaEa9",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZXT3WCbmq8C",
        "colab_type": "code",
        "outputId": "1962e8f7-6657-4803-da03-01119d0f4d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# import numpy as np\n",
        "# from sklearn import datasets\n",
        "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Activation\n",
        "# from keras.utils import to_categorical\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "# X= iris.data\n",
        "# #Y = to_categorical(iris.target,3)\n",
        "# Y = iris.target\n",
        "\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=1000)\n",
        "\n",
        "# def create_model(optimizer='rmsprop'):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(8,activation='relu',input_shape = (4,)))\n",
        "#     model.add(Dense(3,activation='softmax'))\n",
        "#     model.compile(optimizer = optimizer,\n",
        "#                   loss='categorical_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "\n",
        "# model = KerasClassifier(build_fn=create_model,\n",
        "#                         epochs=10, \n",
        "#                         batch_size=5,\n",
        "#                         verbose=0)\n",
        "\n",
        "# #results = cross_val_score(model, X_train, Y_train, scoring='precision_macro')\n",
        "\n",
        "# param_grid = {'optimizer':('rmsprop','adam')}\n",
        "# grid = GridSearchCV(model,\n",
        "#                     param_grid=param_grid,\n",
        "#                     return_train_score=True,\n",
        "#                    scoring=['precision_macro','recall_macro','f1_macro'],\n",
        "#                     refit='precision_macro')\n",
        "# grid_results = grid.fit(X_train,Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_l1oXixMwTg",
        "colab_type": "code",
        "outputId": "dacff92b-5b7f-4622-da34-b58414f495c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "# from vecstack import stacking\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# # Get your data\n",
        "\n",
        "# # Initialize 1st level estimators\n",
        "# models = [LinearRegression(),\n",
        "#           grid_results]\n",
        "\n",
        "# # Get your stacked features in a single line\n",
        "# S_train, S_test = stacking(models, X_train, y_train, X_test, regression=True, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [regression]\n",
            "metric:       [mean_absolute_error]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [2]\n",
            "\n",
            "model  0:     [LinearRegression]\n",
            "    fold  0:  [0.50044260]\n",
            "    fold  1:  [0.49857519]\n",
            "    fold  2:  [0.49963762]\n",
            "    fold  3:  [0.49879974]\n",
            "    ----\n",
            "    MEAN:     [0.49936379] + [0.00073805]\n",
            "    FULL:     [0.49936379]\n",
            "\n",
            "model  1:     [GridSearchCV]\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV] optimizer=adam ..................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " - 13s - loss: 0.4466 - acc: 0.7797\n",
            "Epoch 2/2\n",
            " - 9s - loss: 0.2534 - acc: 0.8965\n",
            "[CV] ................................... optimizer=adam, total=  32.1s\n",
            "[CV] optimizer=adam ..................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " - 13s - loss: 0.4648 - acc: 0.7674\n",
            "Epoch 2/2\n",
            " - 9s - loss: 0.2625 - acc: 0.8929\n",
            "[CV] ................................... optimizer=adam, total=  31.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " - 23s - loss: 0.3983 - acc: 0.8124\n",
            "Epoch 2/2\n",
            " - 19s - loss: 0.2351 - acc: 0.9051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-216c11d16835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get your stacked features in a single line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mS_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vecstack/core.py\u001b[0m in \u001b[0;36mstacking\u001b[0;34m(models, X_train, y_train, X_test, sample_weight, regression, transform_target, transform_pred, mode, needs_proba, save_dir, metric, n_folds, stratified, shuffle, random_state, verbose)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                         \u001b[0mcol_slice_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                     \u001b[0mS_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_slice_model\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0;31m# Predict full test set in each fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (6250,1) could not be broadcast to indexing result of shape (6250,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8okbVRL-_0",
        "colab_type": "code",
        "outputId": "9344a8d6-40aa-4cdb-94be-8553da22d536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "# # set parameters:\n",
        "# max_features = 5000\n",
        "# maxlen = 500\n",
        "# batch_size = 32\n",
        "# embedding_dims = 50\n",
        "# filters = 250\n",
        "# kernel_size = 3\n",
        "# hidden_dims = 250\n",
        "# epochs = 2\n",
        "\n",
        "# print('Loading data...')\n",
        "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "# print(len(x_train), 'train sequences')\n",
        "# print(len(x_test), 'test sequences')\n",
        "\n",
        "# print('Pad sequences (samples x time)')\n",
        "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print('x_test shape:', x_test.shape)\n",
        "\n",
        "# print('Build model...')\n",
        "# model = Sequential()\n",
        "\n",
        "# # we start off with an efficient embedding layer which maps\n",
        "# # our vocab indices into embedding_dims dimensions\n",
        "# model.add(Embedding(max_features,\n",
        "#                     embedding_dims,\n",
        "#                     input_length=maxlen))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # we add a Convolution1D, which will learn filters\n",
        "# # word group filters of size filter_length:\n",
        "# model.add(Conv1D(filters,\n",
        "#                  kernel_size,\n",
        "#                  padding='valid',\n",
        "#                  activation='relu',\n",
        "#                  strides=1))\n",
        "# # we use max pooling:\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# # We add a vanilla hidden layer:\n",
        "# model.add(Dense(hidden_dims))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "# model.add(Dense(1))\n",
        "# model.add(Activation('sigmoid'))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 500)\n",
            "x_test shape: (25000, 500)\n",
            "Build model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 498, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 251       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 350,751\n",
            "Trainable params: 350,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 6s 234us/step - loss: 0.4071 - acc: 0.7990 - val_loss: 0.2810 - val_acc: 0.8816\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 5s 219us/step - loss: 0.2355 - acc: 0.9066 - val_loss: 0.2595 - val_acc: 0.8923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f896abfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}
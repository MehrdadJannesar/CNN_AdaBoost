{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Payan_name_mehrdad.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fnWD92MoaEa9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadJannesar/CNN_AdaBoost/blob/master/Payan_name_mehrdad_Clear_Codes_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DrrMZBR3u8",
        "colab_type": "code",
        "outputId": "067b6e13-3da6-411f-d0e8-17dcdf8ac41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (41.6.0)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEVpxY6lP14f",
        "colab_type": "code",
        "outputId": "f47837b5-5c5c-4550-a2de-b6aa588761a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "from keras.models import Model,Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense, Activation,Dropout,Conv1D,GlobalMaxPooling1D,GRU,Bidirectional,LSTM,SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K \n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn import model_selection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1w9nDwwhTAT",
        "colab_type": "code",
        "outputId": "0923ef75-2e2c-4a7f-ddd9-e4953cc0b6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# set parameters:\n",
        "max_features = 5000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 2\n",
        "embedding_vecor_length = 32\n",
        "units = 128\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "i=0\n",
        "\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qcdGwoDSC7u",
        "colab_type": "text"
      },
      "source": [
        "## Create Models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fWeENwJgMuB",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blSwy1ONf4c3",
        "colab_type": "code",
        "outputId": "127ffe64-7973-4ff0-d6e5-cfe4a91f53e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_BG(optimizer='adam'):\n",
        "  model_BG = Sequential()\n",
        "  model_BG.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BG.add(Bidirectional(GRU(100)))\n",
        "  model_BG.add(Dense(1, activation='sigmoid'))\n",
        "  model_BG.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model_BG\n",
        "\n",
        "\n",
        "model_BG = KerasClassifier(build_fn=fit_model_BG,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BG_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BG_grid = GridSearchCV(model_BG,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BG_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BG_summary = fit_model_BG()\n",
        "print(model_BG_summary.summary())\n",
        "\n",
        "\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BG.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BG = model_BG.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_GRU = np.argmax(X_test, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 200)               79800     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 240,001\n",
            "Trainable params: 240,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-v2UwM6ggDK",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMoGUHcbgkPL",
        "colab_type": "code",
        "outputId": "a43e7001-1e8b-4d99-a3af-adb4e1949114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_BL(optimizer='adam'):\n",
        "  model_BL = Sequential()\n",
        "  model_BL.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BL.add(Bidirectional(LSTM(100)))\n",
        "  model_BL.add(Dense(1, activation='sigmoid'))\n",
        "  model_BL.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model_BL\n",
        "\n",
        "model_BL = KerasClassifier(build_fn=fit_model_BL,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BL_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BL_grid = GridSearchCV(model_BL,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BL_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BL_summary = fit_model_BL()\n",
        "print(model_BL_summary.summary())\n",
        "\n",
        "# print(model_BL.summary())\n",
        "# model_BL.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BL.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BL = model_BL.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_LSTM = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 200)               106400    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 266,601\n",
            "Trainable params: 266,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9J0iwYyguNJ",
        "colab_type": "text"
      },
      "source": [
        "# Bidirection_RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6YkGa1jgwvo",
        "colab_type": "code",
        "outputId": "5b11b690-5faf-4076-8ffe-7afc763a4b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_BR(optimizer='adam'):\n",
        "  model_BR = Sequential()\n",
        "  model_BR.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_BR.add(Bidirectional(SimpleRNN(100)))\n",
        "  model_BR.add(Dense(1, activation='sigmoid'))\n",
        "  model_BR.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_BR\n",
        "\n",
        "model_BR = KerasClassifier(build_fn=fit_model_BR,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_BR_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_BR_grid = GridSearchCV(model_BR,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_BR_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_BR_summary = fit_model_BR()\n",
        "print(model_BR_summary.summary())\n",
        "\n",
        "\n",
        "# print(model_BR.summary())\n",
        "# model_BR.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_BR.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_BR = model_BR.predict(X_test)\n",
        "\n",
        "# test_uniq_Bidirection_RNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 200)               26600     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 186,801\n",
            "Trainable params: 186,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPIK59y1g9OY",
        "colab_type": "text"
      },
      "source": [
        "# LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voXaUD2QhBtg",
        "colab_type": "code",
        "outputId": "e7200d9a-b817-4afa-99b4-0eae7cf5277e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_L(optimizer='adam'):\n",
        "  model_L = Sequential()\n",
        "  model_L.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_L.add(LSTM(100))\n",
        "  model_L.add(Dense(1, activation='sigmoid'))\n",
        "  model_L.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_L\n",
        "\n",
        "model_L = KerasClassifier(build_fn=fit_model_L,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_L_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_L_grid = GridSearchCV(model_L,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_L_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_L_summary = fit_model_L()\n",
        "print(model_L_summary.summary())\n",
        "\n",
        "\n",
        "\n",
        "# print(model_L.summary())\n",
        "# model_L.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_L.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_L = model_L.predict(X_test)\n",
        "\n",
        "# test_uniq_LSTM = np.argmax(X_test, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfRX1cL3hG1d",
        "colab_type": "text"
      },
      "source": [
        "# SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFXukTQhhKQI",
        "colab_type": "code",
        "outputId": "6f15a770-78f7-4d21-b862-e2140676a741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_SR(optimizer='adam'):\n",
        "  model_SR = Sequential()\n",
        "  model_SR.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_SR.add(SimpleRNN(100))\n",
        "  model_SR.add(Dense(1, activation='sigmoid'))\n",
        "  model_SR.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_SR\n",
        "\n",
        "\n",
        "model_SR = KerasClassifier(build_fn=fit_model_SR,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_SR_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_SR_grid = GridSearchCV(model_SR,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_SR_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_SR_summary = fit_model_SR()\n",
        "print(model_SR_summary.summary())\n",
        "\n",
        "\n",
        "\n",
        "# print(model_SR.summary())\n",
        "# model_SR.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_SR.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_SR = model_SR.predict(X_test)\n",
        "\n",
        "# test_uniq_SimpleRNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 100)               13300     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVNW0Dzv29U3",
        "colab_type": "text"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6iAuwFSkc2G",
        "colab_type": "code",
        "outputId": "d2eaf990-8d2a-477a-c67f-9de35510ec29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "def fit_model_GRU(optimizer='adam'):\n",
        "  model_GRU = Sequential()\n",
        "  model_GRU.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "  model_GRU.add(SimpleRNN(100))\n",
        "  model_GRU.add(Dense(1, activation='sigmoid'))\n",
        "  model_GRU.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model_GRU\n",
        "\n",
        "\n",
        "model_GRU = KerasClassifier(build_fn=fit_model_GRU,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_GRU_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_GRU_grid = GridSearchCV(model_GRU,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_GRU_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "\n",
        "model_GRU_summary = fit_model_GRU()\n",
        "print(model_GRU_summary.summary())\n",
        "\n",
        "\n",
        "# print(model_GRU.summary())\n",
        "# model_GRU.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "# # Final evaluation of the model\n",
        "# scores = model_GRU.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# prediction_GRU = model_GRU.predict(X_test)\n",
        "\n",
        "# test_uniq_SimpleRNN = np.argmax(X_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_16 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_6 (SimpleRNN)     (None, 100)               13300     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 173,401\n",
            "Trainable params: 173,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoaICbw7ZXLL",
        "colab_type": "text"
      },
      "source": [
        "## LSTM ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0DUTDNNErrf",
        "colab_type": "code",
        "outputId": "ce1ed853-2d7f-4e5e-f48e-789b8c34c232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "def fit_model_L_A(optimizer='adam'):\n",
        "  input_ = keras.layers.Input(shape=[max_review_length], dtype='int32')\n",
        "\n",
        "  # get the embedding layer\n",
        "  embedded = Embedding(\n",
        "          input_dim=top_words,\n",
        "          output_dim=32,\n",
        "          input_length=max_review_length,\n",
        "          trainable=False,\n",
        "          mask_zero=False\n",
        "      )(input_)\n",
        "\n",
        "  activations = LSTM(units, return_sequences=True)(embedded)\n",
        "\n",
        "  # compute importance for each step\n",
        "  attention = Dense(1, activation='tanh')(activations)\n",
        "  attention = keras.layers.Flatten()(attention)\n",
        "  attention = keras.layers.Activation('softmax')(attention)\n",
        "  attention = keras.layers.RepeatVector(units)(attention)\n",
        "  attention = keras.layers.Permute([2, 1])(attention)\n",
        "\n",
        "  multiply_layer = keras.layers.Multiply()\n",
        "  sent_representation = multiply_layer([activations, attention])\n",
        "  # sent_representation = keras.layers.Multiply([activations, attention])\n",
        "  sent_representation = keras.layers.Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(sent_representation)\n",
        "\n",
        "  probabilities = Dense(1, activation='sigmoid')(sent_representation)\n",
        "  model_L_A = Model(input=input_, output=probabilities)\n",
        "  model_L_A.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "\n",
        "  return model_L_A\n",
        "\n",
        "\n",
        "\n",
        "model_L_A = KerasClassifier(build_fn=fit_model_L_A,\n",
        "                        epochs=3, \n",
        "                        batch_size=64,\n",
        "                        verbose=2)\n",
        "  \n",
        "model_L_A_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_L_A_grid = GridSearchCV(model_L_A,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_L_A_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "model_L_A_summary = fit_model_L_A()\n",
        "print(model_L_A_summary.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 500)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 500, 32)      160000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 500, 128)     82432       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 500, 1)       129         lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 500)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 500)          0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 128, 500)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 500, 128)     0           repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 500, 128)     0           lstm_1[0][0]                     \n",
            "                                                                 permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 128)          0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 242,690\n",
            "Trainable params: 82,690\n",
            "Non-trainable params: 160,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TnzD2dub2PI",
        "colab_type": "text"
      },
      "source": [
        "# Text_CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMaib8lHotb2",
        "colab_type": "code",
        "outputId": "68b7f90d-9491-4210-dd83-e4f3e661f9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "def fit_model_text_CNN(optimizer='adam'):\n",
        "  model_text_CNN = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "  model_text_CNN.add(Embedding(max_features,\n",
        "                      embedding_dims,\n",
        "                      input_length=maxlen))\n",
        "  model_text_CNN.add(Dropout(0.2))\n",
        "\n",
        "  # we add a Convolution1D, which will learn filters\n",
        "  # word group filters of size filter_length:\n",
        "  model_text_CNN.add(Conv1D(filters,\n",
        "                  kernel_size,\n",
        "                  padding='SAME',\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  # we use max pooling:\n",
        "  model_text_CNN.add(GlobalMaxPooling1D())\n",
        "\n",
        "  # We add a vanilla hidden layer:\n",
        "  model_text_CNN.add(Dense(hidden_dims))\n",
        "  model_text_CNN.add(Dropout(0.2))\n",
        "  model_text_CNN.add(Activation('relu'))\n",
        "\n",
        "  # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "  model_text_CNN.add(Dense(1))\n",
        "  model_text_CNN.add(Activation('sigmoid'))\n",
        "\n",
        "  model_text_CNN.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model_text_CNN\n",
        "\n",
        "\n",
        "model_text_CNN = KerasClassifier(build_fn=fit_model_text_CNN,\n",
        "                        epochs=1, \n",
        "                        batch_size=5,\n",
        "                        verbose=2)\n",
        "  \n",
        "\n",
        "model_text_CNN_param_grid = {'optimizer':['adam']}\n",
        "\n",
        "model_text_CNN_grid = GridSearchCV(model_text_CNN,cv=KFold(n_splits=2),\n",
        "                    param_grid=model_text_CNN_param_grid,\n",
        "                    return_train_score=True,\n",
        "                    scoring=['accuracy'],\n",
        "                    refit='accuracy')\n",
        "\n",
        "model_text_CNN_summary = fit_model_text_CNN()\n",
        "print(model_text_CNN_summary.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 50)           250000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 500, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 251       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 350,751\n",
            "Trainable params: 350,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNx3D8RRWxJz",
        "colab_type": "text"
      },
      "source": [
        "# StackingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2vvXmpBZ23l",
        "colab_type": "text"
      },
      "source": [
        "## Running GridSearch Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxd2RvEPlR-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_BG_grid_results = model_BG_grid.fit(X_train, y_train)\n",
        "i = 0\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5cG5jEm3g1R",
        "colab_type": "code",
        "outputId": "b4bc4fb6-6d3c-4d76-fe20-9f3717a580e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_BG_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7eed0ed7f0>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bTwZ-YIlR58",
        "colab_type": "code",
        "outputId": "100771f1-770b-4e31-8f8c-99e05ed28758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_BL_grid_results = model_BL_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGh_vrAr3nH9",
        "colab_type": "code",
        "outputId": "2fae76a9-03be-4f7b-b26d-8da3335ce1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_BL_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7e9485ca20>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E5YJELulR2q",
        "colab_type": "code",
        "outputId": "0ead12fb-19b8-470e-d8dc-8ca74da8cb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_BR_grid_results = model_BR_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS21QBaQ3o99",
        "colab_type": "code",
        "outputId": "4f3bddd6-a839-4602-f13d-bfad43a6f348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_BR_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7e946abc18>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzZGauQlR0C",
        "colab_type": "code",
        "outputId": "a6c15960-ebde-404b-98f4-4295344ec878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_L_grid_results = model_L_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTC8qDey3qMT",
        "colab_type": "code",
        "outputId": "281337f8-a31b-4c65-de86-99462bc79c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_L_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7e945f3860>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUmsf-6wlRxf",
        "colab_type": "code",
        "outputId": "b73b8cfb-94c2-4848-9c3e-ed8fd04421d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_SR_grid_results = model_SR_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Pezudu3roy",
        "colab_type": "code",
        "outputId": "42dc5921-b483-4e51-a442-1886dabf3ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_SR_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7e944e7470>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7RnoW8VlRve",
        "colab_type": "code",
        "outputId": "1b4ea1ac-6254-4d64-c0a0-ea1ded00b324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_GRU_grid_results = model_GRU_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njxshf163tCB",
        "colab_type": "code",
        "outputId": "e3f265cc-18f4-4256-ff7d-77bfa3804e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_GRU_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f7e944e2a90>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jMozIxTlRtK",
        "colab_type": "code",
        "outputId": "2a400ea9-c553-43de-f1e9-f5c3b0f73365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_L_A_grid_results = model_L_A_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Is Okaye!\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQTx2PCe3uow",
        "colab_type": "code",
        "outputId": "f24087c5-b4e9-493d-baef-71514fe48a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_L_A_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f629f1d86d8>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgX_I9iKlRqK",
        "colab_type": "code",
        "outputId": "e7d599e9-0d14-43ac-e9bd-8e1f0499aa9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model_text_CNN_grid_results = model_text_CNN_grid.fit(X_train, y_train)\n",
        "clear_output(wait=False)\n",
        "i += 1 \n",
        "print(i , \"Is Okaye!\")\n",
        "print('='*20)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 Is Okaye!\n",
            "====================\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCItBjZA3vnx",
        "colab_type": "code",
        "outputId": "d02f2789-5b5b-4385-f086-9428a351e7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "model_text_CNN_grid_results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
              "             error_score='raise-deprecating',\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f62971fca58>,\n",
              "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
              "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "             scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lYjsc29W01D",
        "colab_type": "text"
      },
      "source": [
        "## Stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbtFKnDBMxkl",
        "colab_type": "code",
        "outputId": "0e678c49-d192-45f4-ac3d-ed96d3d7ed05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model_BG_grid_results_clf = model_BG_grid_results\n",
        "# model_BL_grid_results_clf = model_BL_grid_results\n",
        "# model_BR_grid_results_clf = model_BR_grid_results\n",
        "# model_L_grid_results_clf = model_L_grid_results\n",
        "# model_SR_grid_results_clf = model_SR_grid_results\n",
        "# model_GRU_grid_results_clf = model_GRU_grid_results\n",
        "model_L_A_grid_results_clf = model_L_A_grid_results\n",
        "model_text_CNN_grid_results_clf = model_text_CNN_grid_results\n",
        "\n",
        "# Logit will be used for stacking\n",
        "lr = LogisticRegression(solver='lbfgs')\n",
        "sclf = StackingCVClassifier(classifiers=[#model_BG_grid_results_clf\n",
        "                                        #  ,model_BL_grid_results_clf\n",
        "                                        #  ,model_BR_grid_results_clf\n",
        "                                        #  ,model_L_grid_results_clf\n",
        "                                        #  ,model_SR_grid_results_clf\n",
        "                                        #  ,model_GRU_grid_results_clf\n",
        "                                         model_L_A_grid_results_clf\n",
        "                                         ,model_text_CNN_grid_results_clf], \n",
        "                            meta_classifier=lr, use_probas=True, cv=2)\n",
        "\n",
        "# Do CV\n",
        "for clf, label in zip([#model_BG_grid_results_clf\n",
        "                                        #  ,model_BL_grid_results_clf\n",
        "                                        #  ,model_BR_grid_results_clf\n",
        "                                        #  ,model_L_grid_results_clf\n",
        "                                        #  ,model_SR_grid_results_clf\n",
        "                                        #  ,model_GRU_grid_results_clf\n",
        "                                         model_L_A_grid_results_clf\n",
        "                                         ,model_text_CNN_grid_results_clf, sclf], \n",
        "                      [#'Bidirection_GRU', \n",
        "                      #  'Bidirection_LSTM', \n",
        "                      #  'Bidirection_RNN',\n",
        "                      #  'LSTM',\n",
        "                      #  'Simple_RNN',\n",
        "                      #  'GRU',\n",
        "                       'LSTM_Attention',\n",
        "                       'Text_CNN']):\n",
        "\n",
        "    scores = model_selection.cross_val_score(clf, X_train, y_train, cv=2, scoring='roc_auc')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "\n",
        "# Fit on train data / predict on test data\n",
        "sclf_fit = sclf.fit(X_train, y_train)\n",
        "mypreds = sclf_fit.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 66s - loss: 0.6933 - acc: 0.5048\n",
            "Epoch 2/3\n",
            " - 64s - loss: 0.6931 - acc: 0.5059\n",
            "Epoch 3/3\n",
            " - 65s - loss: 0.6929 - acc: 0.5062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 68s - loss: 0.6935 - acc: 0.5086\n",
            "Epoch 2/3\n",
            " - 65s - loss: 0.6929 - acc: 0.5157\n",
            "Epoch 3/3\n",
            " - 65s - loss: 0.6956 - acc: 0.5115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 143s - loss: 0.6930 - acc: 0.5074\n",
            "Epoch 2/3\n",
            " - 139s - loss: 0.6932 - acc: 0.5074\n",
            "Epoch 3/3\n",
            " - 137s - loss: 0.6952 - acc: 0.5120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 68s - loss: 0.6934 - acc: 0.4968\n",
            "Epoch 2/3\n",
            " - 64s - loss: 0.6935 - acc: 0.5027\n",
            "Epoch 3/3\n",
            " - 63s - loss: 0.6932 - acc: 0.4973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 67s - loss: 0.6934 - acc: 0.5037\n",
            "Epoch 2/3\n",
            " - 64s - loss: 0.6934 - acc: 0.5010\n",
            "Epoch 3/3\n",
            " - 64s - loss: 0.6930 - acc: 0.5016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 128s - loss: 0.6933 - acc: 0.5015\n",
            "Epoch 2/3\n",
            " - 129s - loss: 0.6931 - acc: 0.5042\n",
            "Epoch 3/3\n",
            " - 126s - loss: 0.6931 - acc: 0.5121\n",
            "Accuracy: 0.52 (+/- 0.01) [LSTM_Attention]\n",
            "Epoch 1/1\n",
            " - 8s - loss: 0.5013 - acc: 0.7400\n",
            "Epoch 1/1\n",
            " - 9s - loss: 0.5274 - acc: 0.7010\n",
            "Epoch 1/1\n",
            " - 14s - loss: 0.4215 - acc: 0.7926\n",
            "Epoch 1/1\n",
            " - 9s - loss: 0.5065 - acc: 0.7253\n",
            "Epoch 1/1\n",
            " - 9s - loss: 0.5081 - acc: 0.7208\n",
            "Epoch 1/1\n",
            " - 15s - loss: 0.4326 - acc: 0.7858\n",
            "Accuracy: 0.95 (+/- 0.00) [Text_CNN]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 69s - loss: 0.6933 - acc: 0.4949\n",
            "Epoch 2/3\n",
            " - 65s - loss: 0.6932 - acc: 0.5045\n",
            "Epoch 3/3\n",
            " - 64s - loss: 0.6931 - acc: 0.5114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 67s - loss: 0.6933 - acc: 0.5008\n",
            "Epoch 2/3\n",
            " - 64s - loss: 0.6931 - acc: 0.5018\n",
            "Epoch 3/3\n",
            " - 64s - loss: 0.6931 - acc: 0.5026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 132s - loss: 0.6932 - acc: 0.5032\n",
            "Epoch 2/3\n",
            " - 129s - loss: 0.6931 - acc: 0.5098\n",
            "Epoch 3/3\n",
            " - 129s - loss: 0.6945 - acc: 0.4999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 69s - loss: 0.6933 - acc: 0.5101\n",
            "Epoch 2/3\n",
            " - 65s - loss: 0.6931 - acc: 0.5083\n",
            "Epoch 3/3\n",
            " - 65s - loss: 0.6932 - acc: 0.5024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 70s - loss: 0.6935 - acc: 0.5003\n",
            "Epoch 2/3\n",
            " - 65s - loss: 0.6931 - acc: 0.5050\n",
            "Epoch 3/3\n",
            " - 65s - loss: 0.6931 - acc: 0.5058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 139s - loss: 0.6933 - acc: 0.4986\n",
            "Epoch 2/3\n",
            " - 133s - loss: 0.6931 - acc: 0.5122\n",
            "Epoch 3/3\n",
            " - 136s - loss: 0.6927 - acc: 0.5154\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.5098 - acc: 0.7306\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.5077 - acc: 0.7323\n",
            "Epoch 1/1\n",
            " - 17s - loss: 0.4270 - acc: 0.7929\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.4917 - acc: 0.7462\n",
            "Epoch 1/1\n",
            " - 11s - loss: 0.4958 - acc: 0.7355\n",
            "Epoch 1/1\n",
            " - 18s - loss: 0.4205 - acc: 0.7918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 142s - loss: 0.6933 - acc: 0.5011\n",
            "Epoch 2/3\n",
            " - 137s - loss: 0.6930 - acc: 0.5114\n",
            "Epoch 3/3\n",
            " - 136s - loss: 0.6930 - acc: 0.5150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 139s - loss: 0.6932 - acc: 0.5078\n",
            "Epoch 2/3\n",
            " - 132s - loss: 0.6930 - acc: 0.5050\n",
            "Epoch 3/3\n",
            " - 132s - loss: 0.6931 - acc: 0.5119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            " - 272s - loss: 0.6928 - acc: 0.5069\n",
            "Epoch 2/3\n",
            " - 265s - loss: 0.6930 - acc: 0.5118\n",
            "Epoch 3/3\n",
            " - 266s - loss: 0.6931 - acc: 0.5179\n",
            "Epoch 1/1\n",
            " - 19s - loss: 0.4306 - acc: 0.7801\n",
            "Epoch 1/1\n",
            " - 18s - loss: 0.4252 - acc: 0.7922\n",
            "Epoch 1/1\n",
            " - 31s - loss: 0.3690 - acc: 0.8287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfT3Nw9flc44",
        "colab_type": "code",
        "outputId": "31b2d484-2105-4493-ca32-f61e367d8a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        }
      },
      "source": [
        "print(sclf_fit)\n",
        "print(mypreds)\n",
        "print(model_text_CNN_grid_results_clf)\n",
        "print(model_L_A_grid_results_clf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StackingCVClassifier(classifiers=[GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
            "                                               error_score='raise-deprecating',\n",
            "                                               estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f629f1d86d8>,\n",
            "                                               iid='warn', n_jobs=None,\n",
            "                                               param_grid={'optimizer': ['adam']},\n",
            "                                               pre_dispatch='2*n_jobs',\n",
            "                                               refit='accuracy',\n",
            "                                               return_train_score=True,\n",
            "                                               scoring=['accuracy...\n",
            "                     meta_classifier=LogisticRegression(C=1.0,\n",
            "                                                        class_weight=None,\n",
            "                                                        dual=False,\n",
            "                                                        fit_intercept=True,\n",
            "                                                        intercept_scaling=1,\n",
            "                                                        l1_ratio=None,\n",
            "                                                        max_iter=100,\n",
            "                                                        multi_class='warn',\n",
            "                                                        n_jobs=None,\n",
            "                                                        penalty='l2',\n",
            "                                                        random_state=None,\n",
            "                                                        solver='lbfgs',\n",
            "                                                        tol=0.0001, verbose=0,\n",
            "                                                        warm_start=False),\n",
            "                     shuffle=True, store_train_meta_features=False,\n",
            "                     stratify=True, use_clones=True,\n",
            "                     use_features_in_secondary=False, use_probas=True,\n",
            "                     verbose=0)\n",
            "[[0.95726671 0.04273329]\n",
            " [0.04180438 0.95819562]\n",
            " [0.26535604 0.73464396]\n",
            " ...\n",
            " [0.62699538 0.37300462]\n",
            " [0.90670116 0.09329884]\n",
            " [0.31358933 0.68641067]]\n",
            "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
            "             error_score='raise-deprecating',\n",
            "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f62971fca58>,\n",
            "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
            "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
            "             scoring=['accuracy'], verbose=0)\n",
            "GridSearchCV(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
            "             error_score='raise-deprecating',\n",
            "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f629f1d86d8>,\n",
            "             iid='warn', n_jobs=None, param_grid={'optimizer': ['adam']},\n",
            "             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
            "             scoring=['accuracy'], verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnWD92MoaEa9",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQWezuUKsQh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import itertools\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn import svm, datasets\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# conf_mat = confusion_matrix(mypreds, y_test)\n",
        "# acc = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "# print('Overall accuracy: {} %'.format(acc*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZXT3WCbmq8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# from sklearn import datasets\n",
        "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Activation\n",
        "# from keras.utils import to_categorical\n",
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "# X= iris.data\n",
        "# #Y = to_categorical(iris.target,3)\n",
        "# Y = iris.target\n",
        "\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=1000)\n",
        "\n",
        "# def create_model(optimizer='rmsprop'):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(8,activation='relu',input_shape = (4,)))\n",
        "#     model.add(Dense(3,activation='softmax'))\n",
        "#     model.compile(optimizer = optimizer,\n",
        "#                   loss='categorical_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "\n",
        "# model = KerasClassifier(build_fn=create_model,\n",
        "#                         epochs=10, \n",
        "#                         batch_size=5,\n",
        "#                         verbose=0)\n",
        "\n",
        "# #results = cross_val_score(model, X_train, Y_train, scoring='precision_macro')\n",
        "\n",
        "# param_grid = {'optimizer':('rmsprop','adam')}\n",
        "# grid = GridSearchCV(model,\n",
        "#                     param_grid=param_grid,\n",
        "#                     return_train_score=True,\n",
        "#                    scoring=['precision_macro','recall_macro','f1_macro'],\n",
        "#                     refit='precision_macro')\n",
        "# grid_results = grid.fit(X_train,Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_l1oXixMwTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from vecstack import stacking\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# # Get your data\n",
        "\n",
        "# # Initialize 1st level estimators\n",
        "# models = [LinearRegression(),\n",
        "#           grid_results]\n",
        "\n",
        "# # Get your stacked features in a single line\n",
        "# S_train, S_test = stacking(models, X_train, y_train, X_test, regression=True, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8okbVRL-_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # set parameters:\n",
        "# max_features = 5000\n",
        "# maxlen = 500\n",
        "# batch_size = 32\n",
        "# embedding_dims = 50\n",
        "# filters = 250\n",
        "# kernel_size = 3\n",
        "# hidden_dims = 250\n",
        "# epochs = 2\n",
        "\n",
        "# print('Loading data...')\n",
        "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "# print(len(x_train), 'train sequences')\n",
        "# print(len(x_test), 'test sequences')\n",
        "\n",
        "# print('Pad sequences (samples x time)')\n",
        "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print('x_test shape:', x_test.shape)\n",
        "\n",
        "# print('Build model...')\n",
        "# model = Sequential()\n",
        "\n",
        "# # we start off with an efficient embedding layer which maps\n",
        "# # our vocab indices into embedding_dims dimensions\n",
        "# model.add(Embedding(max_features,\n",
        "#                     embedding_dims,\n",
        "#                     input_length=maxlen))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# # we add a Convolution1D, which will learn filters\n",
        "# # word group filters of size filter_length:\n",
        "# model.add(Conv1D(filters,\n",
        "#                  kernel_size,\n",
        "#                  padding='valid',\n",
        "#                  activation='relu',\n",
        "#                  strides=1))\n",
        "# # we use max pooling:\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# # We add a vanilla hidden layer:\n",
        "# model.add(Dense(hidden_dims))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "# model.add(Dense(1))\n",
        "# model.add(Activation('sigmoid'))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}